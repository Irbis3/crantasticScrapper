# Aggregate k-nearest neighbor algorithms
readData <- function(src,col,reader=read.csv,
                     header=FALSE,stringAsFactors=FALSE,
                     plot=TRUE,...) {
  data <- reader(src,header=header,stringAsFactors=stringAsFactors,...)
  if(plot) plot(data,type="l")
  return(data)
}

simData <- function(n=NA,fun=rnorm,args=list(),plot=T) {
  if(is.numeric(n)) {
    data <- as.numeric(do.call(fun,c(n=n,args)))
  } else {
    data <- as.numeric(do.call(fun,args))
  }
  if(plot) plot(data,type="l")
  return(data)
}

kPredicts <- function(data,hs,k,n.ahead=1,min.cor=0) {
  kPredict <- function(data,k,h,n.ahead,min.cor=0,
                       output=c("predicts","estimate","error"),
                       local.model=lm) {
    n <- length(data)
    series <- data[(n-h+1):n]
    range <- 1:(n-h-n.ahead+1)
    cors <- sapply(range,function(i) {
      pattern <- data[i:(i+h-1)]
      return(cor(pattern,series))
    })
    abs.cors <- abs(cors)
    orders <- order(abs.cors,decreasing=T)
    # FIXME: orders <= k does not gurantee the number of nearest neighbors.
    indices <- range[orders<=k & abs.cors>=min.cor]

    predicts <- t(sapply(indices,function(i) {
      pattern <- data[i:(i+h-1)]
      predictor <- data[(i+h):(i+h+n.ahead-1)]
      m <- local.model(series~pattern+I(pattern^2))
      coeff <- coef(m)
      predictor <- coeff[[1]]+
        coeff[[2]]*predictor+
        coeff[[3]]*predictor^2
      return(predictor)
    }))

    corsi <- cors[indices]
    abs.corsi <- abs(corsi)
    estimate <- sapply(1:n.ahead,function(t) {
      w <- exp(abs.corsi)
      sumw <- sum(w)
      preds <- w*predicts[,t]/sumw
      pred <- sum(preds)
      sd <- sd(preds)
      rsd <- sd/abs(pred)
      return(c(pred=pred,sd=sd,rsd=rsd))
    })
    error <- sum(estimate["sd",])
    result <- list(predicts=predicts,estimate=estimate,error=error)
    return(result[output])
  }

  n <- length(data)
  g <- length(hs)
  groups <- 1:g
  plist <- lapply(hs,function(h) {
    predict <- kPredict(data,h=h,k=k,n.ahead=n.ahead,min.cor=min.cor)
    result <- c(list(h=h),predict)
    return(result)
  })
  errors <- sapply(groups,function(i)plist[[i]]$error)
  orders <- order(errors)
  result <- plist[[groups[orders==1]]]
  return(list(errors=errors,orders=orders,pred=result))
}

# TODO: parallelize the method by passing functions as arguments
kValidate <- function(data,start,hs,k,n.ahead,min.cor=0,print.out=T) {
  n <- length(data)
  range <- start:(n-n.ahead)
  valid <- sapply(range,function(i) {
    vdata <- data[1:i]
    result <- kPredicts(vdata,hs=hs,k=k,n.ahead=n.ahead,min.cor=min.cor)
    pred <- result$pred$estimate["pred",]
    actual <- data[(i+1):(i+n.ahead)]
    residuals <- actual-pred
    mde <- mean(residuals)
    made <- mean(abs(residuals))
    cor <- cor(pred,actual)
    if(print.out) {
      print(i)
    }
    
    return(c(pred,actual=actual,error=residuals,
             mde=mde,made=made,cor=cor))
  })
  return(data.frame(t(valid)))
}

# Issues
# FIXME: The predictor seems biased
# if the data is generated by arima, here we need a comparsion to arima fit
# example: result <- kvalidate(data,1500,hs=seq(3,6),k=100,n.ahead=1,min.cor=0)
kPlot <- function(result) {
  par(mfrow=c(2,2))
  plot(density(result$mde),main="MDE")
  plot(density(result$made),main="MADE")
  plot(result$pred,result$actual)
  plot(result$pred)
  lines(result$actual,col="red")
}

# analyze the performance of the results
kAnalyze <- function(result) {
  m <- lm(actual~pred+0,data=result)
  par(mfrow=c(2,2))
  summary(m)
  plot(m)
  return(m)
}


#TODO: Add ARIMA simulation and step-wise ARIMA model fit.
#TODO: kNN as a binary classifier to predict whether the stock price will go up or down